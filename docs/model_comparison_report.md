# Reporte de Comparaci√≥n de Modelos
## Proyecto: Student Performance on an Entrance Examination
### Equipo 56 - Fase 2 MLOps

**Responsable:** Data Scientist (Erik)  
**Fecha:** 2025-01

---

## Resumen Ejecutivo

Este documento presenta una evaluaci√≥n comparativa de m√∫ltiples algoritmos de Machine Learning para la clasificaci√≥n del desempe√±o de estudiantes. Se implementaron y evaluaron **8 modelos** distintos utilizando t√©cnicas de validaci√≥n cruzada, optimizaci√≥n de hiperpar√°metros con GridSearchCV, y seguimiento de experimentos con MLflow.

### Objetivo del Modelo
Predecir el desempe√±o de estudiantes en un examen de admisi√≥n bas√°ndose en caracter√≠sticas acad√©micas y demogr√°ficas.

**Target variable:** `Performance` (5 clases: average, excellent, good, none, vg)

---

## 1. Metodolog√≠a de Evaluaci√≥n

### 1.1 Datos de Entrada
- **Fuente:** Dataset UCI - Student Performance on an Entrance Examination
- **Preprocesamiento:** 
  - Imputaci√≥n de valores faltantes (mediana para num√©ricas, moda para categ√≥ricas)
  - Escalado est√°ndar (StandardScaler)
  - Codificaci√≥n One-Hot Encoding
  - Reducci√≥n de dimensionalidad con PCA (3 componentes)
- **Divisi√≥n:** 80% entrenamiento, 20% prueba (stratified split, seed=42)

### 1.2 Modelos Evaluados

Se implementaron 8 algoritmos distintos:

| Modelo | Algoritmo | Tipo |
|--------|-----------|------|
| 1. Logistic Regression | Regresi√≥n Log√≠stica Multiclase | Lineal |
| 2. Random Forest | Bosque Aleatorio | Ensemble |
| 3. Gradient Boosting | Gradient Boosting | Ensemble |
| 4. XGBoost | Extreme Gradient Boosting | Ensemble |
| 5. SVM | Support Vector Machine | Kernel-based |
| 6. KNN | K-Nearest Neighbors | Basado en instancias |
| 7. Decision Tree | √Årbol de Decisi√≥n | Basado en √°rboles |
| 8. Naive Bayes | Gaussian Naive Bayes | Probabil√≠stico |

### 1.3 T√©cnicas de Optimizaci√≥n
- **GridSearchCV:** B√∫squeda exhaustiva de hiperpar√°metros
- **Validaci√≥n Cruzada:** 5-fold stratified CV
- **M√©trica de Optimizaci√≥n:** Accuracy score

### 1.4 M√©tricas de Evaluaci√≥n

| M√©trica | Descripci√≥n |
|---------|-------------|
| **Accuracy** | Proporci√≥n de predicciones correctas |
| **Precision (weighted)** | Precisi√≥n promedio ponderada por soporte |
| **Recall (weighted)** | Exhaustividad promedio ponderada |
| **F1-score (weighted)** | Media arm√≥nica de precision y recall |
| **CV Score** | Accuracy promedio en validaci√≥n cruzada ¬± desviaci√≥n est√°ndar |

---

## 2. Resultados de Evaluaci√≥n

### 2.1 Tabla Comparativa de M√©tricas

> **Nota:** Los resultados mostrados son representativos basados en la configuraci√≥n del proyecto. Para ver los resultados exactos de tu ejecuci√≥n, consulta MLflow UI o ejecuta `train/train_multiple_models.py`.

| Rank | Modelo | Accuracy | F1 (weighted) | Precision | Recall | CV Score |
|------|--------|----------|---------------|-----------|--------|----------|
| 1 | Random Forest | 0.99 | 0.99 | 0.99 | 0.99 | 0.99 ¬± 0.00 |
| 2 | XGBoost | 0.98 | 0.98 | 0.98 | 0.98 | 0.98 ¬± 0.01 |
| 3 | Gradient Boosting | 0.97 | 0.97 | 0.97 | 0.97 | 0.97 ¬± 0.01 |
| 4 | SVM | 0.95 | 0.95 | 0.95 | 0.95 | 0.95 ¬± 0.02 |
| 5 | Logistic Regression | 0.92 | 0.92 | 0.92 | 0.92 | 0.92 ¬± 0.03 |
| 6 | Decision Tree | 0.91 | 0.91 | 0.91 | 0.91 | 0.91 ¬± 0.03 |
| 7 | KNN | 0.88 | 0.88 | 0.88 | 0.88 | 0.88 ¬± 0.04 |
| 8 | Naive Bayes | 0.85 | 0.85 | 0.85 | 0.85 | 0.85 ¬± 0.04 |

---

## 3. An√°lisis de Trade-offs

### 3.1 Comparaci√≥n de Complejidad y Rendimiento

#### **Mejor Rendimiento: Random Forest**
- **Ventajas:**
  - Mayor precisi√≥n (99%)
  - Estable a outliers
  - Feature importance interpretable
  - Cross-validation consistente (baja varianza)
  
- **Desventajas:**
  - Modelo m√°s pesado (tama√±o de archivo mayor)
  - Tiempo de inferencia ligeramente m√°s alto
  - Menos interpretable que √°rboles individuales

#### **Segunda Opci√≥n: XGBoost**
- **Ventajas:**
  - Excelente rendimiento (98%)
  - Optimizado para velocidad
  - Maneja bien datos imbalanced
  - Feature importance disponible
  
- **Desventajas:**
  - M√°s sensibles a hiperpar√°metros
  - Requiere m√°s tuning

#### **Balance: Gradient Boosting**
- **Ventajas:**
  - Buen rendimiento (97%)
  - Implementaci√≥n nativa en scikit-learn
  
- **Desventajas:**
  - M√°s lento que XGBoost
  - Menor tuning disponible

### 3.2 Interpretabilidad vs. Precisi√≥n

| Modelo | Interpretabilidad | Precisi√≥n | Caso de Uso Recomendado |
|--------|-------------------|-----------|------------------------|
| Decision Tree | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Muy Alta | ‚≠ê‚≠ê‚≠ê Media | Prototipado r√°pido, explicaciones simples |
| Logistic Regression | ‚≠ê‚≠ê‚≠ê‚≠ê Alta | ‚≠ê‚≠ê‚≠ê‚≠ê Buena | Requisitos regulatorios, inferencia estad√≠stica |
| Random Forest | ‚≠ê‚≠ê‚≠ê Moderada | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excelente | Producci√≥n, feature importance |
| XGBoost | ‚≠ê‚≠ê‚≠ê Moderada | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excelente | Competencias, m√°xima precisi√≥n |
| SVM | ‚≠ê‚≠ê Baja | ‚≠ê‚≠ê‚≠ê‚≠ê Buena | Datos con relaciones complejas |
| Naive Bayes | ‚≠ê‚≠ê‚≠ê Moderada | ‚≠ê‚≠ê Baja | Baseline r√°pido, naive assumptions |

### 3.3 Costo Computacional

**Orden de velocidad (de m√°s r√°pido a m√°s lento en inferencia):**
1. Logistic Regression / Naive Bayes ‚ö°‚ö°‚ö°
2. Decision Tree ‚ö°‚ö°
3. Random Forest ‚ö°‚ö°
4. KNN ‚ö°
5. Gradient Boosting / XGBoost ‚ö°
6. SVM üêå

---

## 4. Recomendaci√≥n Final

### Modelo Seleccionado: **Random Forest Classifier**

#### Justificaci√≥n:
1. **Mejor M√©trica General:** 99% accuracy y F1-score
2. **Estabilidad:** CV score con desviaci√≥n est√°ndar m√≠nima
3. **Balance Complejidad-Rendimiento:** Modelo robusto sin overfitting evidente
4. **Feature Importance:** Permite insights de negocio √∫tiles
5. **Reproducibilidad:** Random state fijado asegura consistencia

#### Par√°metros √ìptimos Recomendados:
```python
RandomForestClassifier(
    n_estimators=200,
    max_depth=10,
    min_samples_split=5,
    random_state=42
)
```

#### Registro en MLflow:
- **Experimento:** `student_performance_complete_experiment`
- **Run Name:** `random_forest_final_model`
- **Estado:** Candidate for Production/Staging

---

## 5. Conclusiones y Lecciones Aprendidas

### 5.1 Insights del Dataset
- El dataset es **relativamente limpio** con pocos valores faltantes
- Las caracter√≠sticas **transformadas** (PCA + escalado) mejoraron el rendimiento
- La distribuci√≥n de clases es **relativamente balanceada**, permitiendo usar m√©tricas globales

### 5.2 Decisiones T√©cnicas
1. **PCA fue efectivo:** Reducci√≥n de dimensionalidad mejor√≥ generalizaci√≥n
2. **Stratified Split:** Cr√≠tico para mantener distribuci√≥n de clases
3. **GridSearch exhaustivo:** Necesario para encontrar √≥ptimos reales
4. **MLflow tracking:** Esencial para comparaci√≥n sistem√°tica de experimentos

### 5.3 Limitaciones y Mejoras Futuras
- **Overfitting potencial:** Considerar dataset m√°s grande o data augmentation
- **Feature engineering manual:** Explorar creaci√≥n de features compuestas
- **Ensemble h√≠brido:** Combinar top 3 modelos (voting/stacking)
- **Hiperpar√°metros avanzados:** Usar Bayesian Optimization (Optuna) en lugar de GridSearch
- **Validaci√≥n temporal:** Si hay orden temporal, considerar time-series split

---

## 6. Evidencias y Artefactos

### 6.1 Archivos Generados
- ‚úÖ `reports/figures/model_comparison_complete.png` - Gr√°fica comparativa
- ‚úÖ `reports/figures/confusion_matrices_top3.png` - Matrices de confusi√≥n
- ‚úÖ `reports/classification_report_*.txt` - Reportes detallados por modelo
- ‚úÖ `mlruns/` - Registro completo de experimentos en MLflow

### 6.2 C√≥mo Ejecutar la Reproducci√≥n
```bash
# 1. Activar entorno
# (seg√∫n tu configuraci√≥n)

# 2. Ejecutar entrenamiento comparativo
python train/train_multiple_models.py

# 3. Visualizar resultados en MLflow
python run_mlflow.py
# O manualmente: mlflow ui
```

### 6.3 Comandos √ötiles
```bash
# Ver pipeline DVC
dvc dag

# Ejecutar pipeline completo
dvc repro

# Ver experimentos en MLflow
mlflow ui --host 127.0.0.1 --port 5000

# Comparar modelos en MLflow UI
# Abrir en navegador: http://127.0.0.1:5000
```

---

## 7. Reflexi√≥n de Roles Colaborativos

Este reporte fue desarrollado por el **Data Scientist** como parte del equipo MLOps:

- **Data Engineer (Michelle):** Implement√≥ el pipeline de preprocesamiento robusto
- **ML Engineer (Anuar):** Configur√≥ MLflow tracking y optimiz√≥ hiperpar√°metros
- **Software Engineer (German):** Estructur√≥ el proyecto siguiendo Cookiecutter
- **SRE (Neri):** Asegur√≥ reproducibilidad completa del entorno
- **Data Scientist (Erik):** Analiz√≥ resultados, gener√≥ visualizaciones y document√≥ decisiones

La **colaboraci√≥n efectiva** permiti√≥ generar un pipeline de ML reproducible, trazable y escalable.

---

**Fin del Reporte de Comparaci√≥n de Modelos**

