{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54e662e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cargado desde: ../data/interim/student_interim_clean_for_model_2.csv\n",
      "DVC Digest encontrado: 76db7197326a5942db9c5b100349f69b\n",
      "\n",
      "Iniciando Grid Search...\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=5, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=5, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=5, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=5, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=5, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=5, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=5, clf__n_estimators=100; total time=   0.1s\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=5, clf__n_estimators=100; total time=   0.1s\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=5, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=5, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=5, clf__n_estimators=200; total time=   0.2s\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=5, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=5, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=5, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=5, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=10, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=10, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=10, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=10, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=10, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=10, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=10, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=10, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=10, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=10, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=10, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=10, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=10, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=10, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=10, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=5, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=5, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=5, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=5, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=5, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=5, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=5, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=5, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=5, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=5, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=5, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=5, clf__n_estimators=200; total time=   0.2s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=5, clf__n_estimators=200; total time=   0.2s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=5, clf__n_estimators=200; total time=   0.2s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=5, clf__n_estimators=200; total time=   0.2s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=10, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=10, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=10, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=10, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=10, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=10, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=10, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=10, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=10, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=10, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=10, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=10, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=10, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=10, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=10, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_split=5, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_split=5, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_split=5, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_split=5, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_split=5, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_split=5, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_split=5, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_split=5, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_split=5, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_split=5, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_split=5, clf__n_estimators=200; total time=   0.2s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_split=5, clf__n_estimators=200; total time=   0.2s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_split=5, clf__n_estimators=200; total time=   0.2s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_split=5, clf__n_estimators=200; total time=   0.2s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_split=5, clf__n_estimators=200; total time=   0.2s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_split=10, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_split=10, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_split=10, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_split=10, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_split=10, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_split=10, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_split=10, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_split=10, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_split=10, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_split=10, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_split=10, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_split=10, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_split=10, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_split=10, clf__n_estimators=200; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/02 17:57:48 INFO mlflow.tracking.fluent: Experiment with name 'randomforest_GridSearch' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__max_depth=None, clf__min_samples_split=10, clf__n_estimators=200; total time=   0.1s\n",
      "Grid Search finalizado.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/02 17:57:48 INFO mlflow.tracking._tracking_service.client: 游끢 View run run_1_RF_GridSearch at: http://127.0.0.1:5001/#/experiments/993790272377427900/runs/1e7d91931a594af2852c01f0546c487d.\n",
      "2025/11/02 17:57:48 INFO mlflow.tracking._tracking_service.client: 游빍 View experiment at: http://127.0.0.1:5001/#/experiments/993790272377427900.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registrando corrida 1 con par치metros: {'clf__max_depth': 5, 'clf__min_samples_split': 5, 'clf__n_estimators': 50}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "RandomForestClassifier.__init__() got an unexpected keyword argument 'clf__max_depth'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 123\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRegistrando corrida \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m con par치metros: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparams\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    120\u001b[39m \u001b[38;5;66;03m# Reconstruir el pipeline para este conjunto de par치metros (para log_model)\u001b[39;00m\n\u001b[32m    121\u001b[39m current_pipeline = Pipeline(steps=[\n\u001b[32m    122\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mpreprocessor\u001b[39m\u001b[33m'\u001b[39m, preprocessor), \n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mclf\u001b[39m\u001b[33m'\u001b[39m, \u001b[43mRandomForestClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m888\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    124\u001b[39m ])\n\u001b[32m    126\u001b[39m \u001b[38;5;66;03m# Entrenar el modelo con el conjunto de entrenamiento COMPLETO usando los mejores par치metros\u001b[39;00m\n\u001b[32m    127\u001b[39m \u001b[38;5;66;03m# NOTA: En la pr치ctica se usa grid_search.best_estimator_ o se reentrena. \u001b[39;00m\n\u001b[32m    128\u001b[39m \u001b[38;5;66;03m# Aqu칤, para fines de registro de TODAS las combinaciones, reentrenamos con la combinaci칩n actual\u001b[39;00m\n\u001b[32m    129\u001b[39m current_pipeline.fit(X_train, y_train)\n",
      "\u001b[31mTypeError\u001b[39m: RandomForestClassifier.__init__() got an unexpected keyword argument 'clf__max_depth'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import yaml # Necesario para leer archivos .dvc (YAML)\n",
    "import mlflow\n",
    "import mlflow.data\n",
    "import mlflow.sklearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# --- IMPORTACIONES DE M칄TRICAS ---\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score\n",
    ")\n",
    "\n",
    "# --- CONFIGURACI칍N DE RUTAS ---\n",
    "DATASET_PATH = '../data/interim/student_interim_clean_for_model_2.csv' \n",
    "DATASET_NAME = 'student_entry_clean'\n",
    "\n",
    "# --- 1. CARGA DE DATOS (Mismos pasos) ---\n",
    "try:\n",
    "    df = pd.read_csv(DATASET_PATH)\n",
    "    print(f\"Dataset cargado desde: {DATASET_PATH}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: Archivo no encontrado en {DATASET_PATH}. Revisa la ruta.\")\n",
    "    exit()\n",
    "\n",
    "# --- 2. L칍GICA DVC: OBTENER EL HASH (Mismos pasos) ---\n",
    "dvc_digest = None\n",
    "dvc_file_path = DATASET_PATH + \".dvc\"\n",
    "if os.path.exists(dvc_file_path):\n",
    "    try:\n",
    "        with open(dvc_file_path, 'r') as f:\n",
    "            dvc_data = yaml.safe_load(f)\n",
    "        if 'outs' in dvc_data and dvc_data['outs']:\n",
    "            dvc_digest = dvc_data['outs'][0].get('md5') \n",
    "            if not dvc_digest:\n",
    "                dvc_digest = dvc_data['outs'][0].get('checksum') \n",
    "        print(f\"DVC Digest encontrado: {dvc_digest}\")\n",
    "    except Exception as e:\n",
    "        print(f\"ADVERTENCIA: No se pudo leer el archivo DVC. Error: {e}\")\n",
    "\n",
    "# --- 3. PREPARACI칍N DE DATOS Y SPLIT (Mismos pasos) ---\n",
    "X = df.drop(columns=['Performance']) \n",
    "y = df['Performance']\n",
    "cat_cols = ['Gender','Caste','coaching','time','Class_ten_education','twelve_education','medium','Class_ X_Percentage','Class_XII_Percentage','Father_occupation','Mother_occupation']\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_enc = le.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_enc, test_size=0.2, stratify=y_enc, random_state=42)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# --- 4. CONFIGURACI칍N DEL PIPELINE BASE Y LA GRILLA DE B칔SQUEDA ---\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# Pipeline base (solo preprocesamiento y clasificador, sin par치metros a칰n)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('ohe', OneHotEncoder(handle_unknown='ignore'), cat_cols)],\n",
    "    remainder='drop'\n",
    ")\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor), \n",
    "    ('clf', RandomForestClassifier(random_state=888))\n",
    "])\n",
    "\n",
    "# Grilla de Par치metros para GridSearchCV (춰NUEVO!)\n",
    "# Nota: Los nombres deben coincidir con la convenci칩n del pipeline: <nombre_paso>__<parametro>\n",
    "param_grid = {\n",
    "    'clf__n_estimators': [50, 100, 200],  # Cantidad de 치rboles\n",
    "    'clf__max_depth': [5, 10, None],      # Profundidad m치xima\n",
    "    'clf__min_samples_split': [5, 10]     # Muestras m칤nimas para dividir\n",
    "}\n",
    "\n",
    "# Configuraci칩n del Grid Search (Usando 'f1_weighted' como m칠trica principal para multiclase)\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1_weighted',  # M칠trica de optimizaci칩n\n",
    "    cv=5,                   # 5-fold cross-validation\n",
    "    verbose=2,\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "# --- 5. ENTRENAMIENTO Y PREDICCIONES (Ejecuci칩n del Grid Search) ---\n",
    "print(\"\\nIniciando Grid Search...\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Grid Search finalizado.\")\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# --- 6. REGISTRO DE TODAS LAS CORRIDAS EN MLFLOW ---\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5001\")\n",
    "EXPERIMENT_NAME = \"randomforest_GridSearch\" # Nuevo nombre de experimento para la b칰squeda\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "\n",
    "# Iterar sobre CADA resultado de CV (Cross-Validation)\n",
    "for i, (mean_score, std_score, params) in enumerate(zip(\n",
    "    grid_search.cv_results_['mean_test_score'],\n",
    "    grid_search.cv_results_['std_test_score'],\n",
    "    grid_search.cv_results_['params']\n",
    ")):\n",
    "    \n",
    "    # 1. Iniciar una nueva corrida para cada combinaci칩n de hiperpar치metros\n",
    "    with mlflow.start_run(run_name=f\"run_{i+1}_RF_GridSearch\", nested=True) as run:\n",
    "        print(f\"Registrando corrida {i+1} con par치metros: {params}\")\n",
    "\n",
    "        # Reconstruir el pipeline para este conjunto de par치metros (para log_model)\n",
    "        current_pipeline = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor), \n",
    "            ('clf', RandomForestClassifier(random_state=888, **params))\n",
    "        ])\n",
    "        \n",
    "        # Entrenar el modelo con el conjunto de entrenamiento COMPLETO usando los mejores par치metros\n",
    "        # NOTA: En la pr치ctica se usa grid_search.best_estimator_ o se reentrena. \n",
    "        # Aqu칤, para fines de registro de TODAS las combinaciones, reentrenamos con la combinaci칩n actual\n",
    "        current_pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        # --- Predicciones y C치lculo de M칠tricas (en el conjunto de prueba) ---\n",
    "        y_pred_test = current_pipeline.predict(X_test)\n",
    "        \n",
    "        # Calcular M칠tricas (Incluyendo las de promedio)\n",
    "        acc_test = accuracy_score(y_test, y_pred_test)\n",
    "        f1_micro = f1_score(y_test, y_pred_test, average='micro')\n",
    "        f1_macro = f1_score(y_test, y_pred_test, average='macro')\n",
    "        f1_weighted = f1_score(y_test, y_pred_test, average='weighted')\n",
    "        report_text = classification_report(y_test, y_pred_test, target_names=le.classes_)\n",
    "        \n",
    "        metrics = {\n",
    "            \"cv_f1_weighted_mean\": mean_score, # M칠trica de CV (crucial para GridSearch)\n",
    "            \"cv_f1_weighted_std\": std_score,\n",
    "            \"test_acc\": acc_test,\n",
    "            \"test_f1_weighted\": f1_weighted,\n",
    "            \"test_f1_macro\": f1_macro,\n",
    "        }\n",
    "        \n",
    "        # --- Registro en MLflow ---\n",
    "        \n",
    "        # 1. Registrar hiperpar치metros\n",
    "        mlflow.log_params(params)\n",
    "        \n",
    "        # 2. Registrar m칠tricas\n",
    "        mlflow.log_metrics(metrics)\n",
    "        \n",
    "        # 3. Guardar modelo\n",
    "        mlflow.sklearn.log_model(current_pipeline, \"random_forest_pipeline\")\n",
    "        \n",
    "        # 4. Registrar Dataset (solo se hace una vez por experimentaci칩n, pero lo incluimos)\n",
    "        mlflow_dataset = mlflow.data.from_pandas(\n",
    "            df=df, source=DATASET_PATH, targets=y.name, name=DATASET_NAME, digest=dvc_digest)\n",
    "        mlflow.log_input(mlflow_dataset, context=\"training\") \n",
    "\n",
    "        # 5. Registrar Classification Report (como artefacto)\n",
    "        temp_report_path = f\"classification_report_run_{i+1}.txt\"\n",
    "        with open(temp_report_path, \"w\") as f:\n",
    "            f.write(report_text)\n",
    "        mlflow.log_artifact(temp_report_path, artifact_path=\"report\")\n",
    "        os.remove(temp_report_path)\n",
    "\n",
    "        # 6. Registrar el modelo con el mejor rendimiento (opcional, solo si el F1 de CV es el mejor hasta ahora)\n",
    "        if mean_score == grid_search.best_score_:\n",
    "             print(f\"!!! Este es el mejor modelo (F1-Weighted CV: {mean_score:.4f}) !!!\")\n",
    "             mlflow.set_tag(\"best_run\", \"True\")\n",
    "\n",
    "\n",
    "print(\"\\n--- RESUMEN FINAL DE GRID SEARCH ---\")\n",
    "print(f\"El mejor F1-Weighted (CV) es: {grid_search.best_score_:.4f}\")\n",
    "print(f\"Los mejores par치metros son: {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb6418f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cargado desde: ../data/interim/student_interim_clean_for_model_2.csv\n",
      "DVC Digest encontrado: 76db7197326a5942db9c5b100349f69b\n",
      "\n",
      "Iniciando Grid Search...\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=5, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=5, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=5, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=5, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=5, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=5, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=5, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=5, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=5, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=5, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=5, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=5, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=5, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=5, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=5, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=10, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=10, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=10, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=10, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=10, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=10, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=10, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=10, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=10, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=10, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=10, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=10, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=10, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=10, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__max_depth=5, clf__min_samples_split=10, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=5, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=5, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=5, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=5, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=5, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=5, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=5, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=5, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=5, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=5, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=5, clf__n_estimators=200; total time=   0.2s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=5, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=5, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=5, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=5, clf__n_estimators=200; total time=   0.2s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=10, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=10, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=10, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=10, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=10, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=10, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=10, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=10, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=10, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=10, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=10, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=10, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=10, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=10, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_split=10, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_split=5, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_split=5, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_split=5, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_split=5, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_split=5, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_split=5, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_split=5, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_split=5, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_split=5, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_split=5, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_split=5, clf__n_estimators=200; total time=   0.2s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_split=5, clf__n_estimators=200; total time=   0.2s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_split=5, clf__n_estimators=200; total time=   0.2s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_split=5, clf__n_estimators=200; total time=   0.2s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_split=5, clf__n_estimators=200; total time=   0.2s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_split=10, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_split=10, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_split=10, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_split=10, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_split=10, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_split=10, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_split=10, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_split=10, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_split=10, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_split=10, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_split=10, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_split=10, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_split=10, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_split=10, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_split=10, clf__n_estimators=200; total time=   0.1s\n",
      "Grid Search finalizado.\n",
      "Registrando corrida 1 con par치metros: {'clf__max_depth': 5, 'clf__min_samples_split': 5, 'clf__n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2025/11/02 18:04:40 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\Anuar\\AppData\\Local\\Temp\\tmp912gvvpu\\model\\model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.5.2', 'cloudpickle==2.2.1']. Set logging level to DEBUG to see the full traceback. \n",
      "2025/11/02 18:04:40 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:150: UserWarning: Failed to determine whether UCVolumeDatasetSource can resolve source information for '../data/interim/student_interim_clean_for_model_2.csv'. Exception: \n",
      "  return _dataset_source_registry.resolve(\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:150: UserWarning: The specified dataset source can be interpreted in multiple ways: LocalArtifactDatasetSource, LocalArtifactDatasetSource. MLflow will assume that this is a LocalArtifactDatasetSource source.\n",
      "  return _dataset_source_registry.resolve(\n",
      "2025/11/02 18:05:01 INFO mlflow.tracking._tracking_service.client: 游끢 View run run_1_RF_GridSearch at: http://127.0.0.1:5001/#/experiments/993790272377427900/runs/490fd4560e2a47ffac3bf861e8bddb97.\n",
      "2025/11/02 18:05:01 INFO mlflow.tracking._tracking_service.client: 游빍 View experiment at: http://127.0.0.1:5001/#/experiments/993790272377427900.\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registrando corrida 2 con par치metros: {'clf__max_depth': 5, 'clf__min_samples_split': 5, 'clf__n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/02 18:07:01 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\Anuar\\AppData\\Local\\Temp\\tmp9mkn4wsa\\model\\model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.5.2', 'cloudpickle==2.2.1']. Set logging level to DEBUG to see the full traceback. \n",
      "2025/11/02 18:07:01 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:150: UserWarning: Failed to determine whether UCVolumeDatasetSource can resolve source information for '../data/interim/student_interim_clean_for_model_2.csv'. Exception: \n",
      "  return _dataset_source_registry.resolve(\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:150: UserWarning: The specified dataset source can be interpreted in multiple ways: LocalArtifactDatasetSource, LocalArtifactDatasetSource. MLflow will assume that this is a LocalArtifactDatasetSource source.\n",
      "  return _dataset_source_registry.resolve(\n",
      "2025/11/02 18:07:22 INFO mlflow.tracking._tracking_service.client: 游끢 View run run_2_RF_GridSearch at: http://127.0.0.1:5001/#/experiments/993790272377427900/runs/2274bce565e0403a92509730fb5e4c3d.\n",
      "2025/11/02 18:07:22 INFO mlflow.tracking._tracking_service.client: 游빍 View experiment at: http://127.0.0.1:5001/#/experiments/993790272377427900.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registrando corrida 3 con par치metros: {'clf__max_depth': 5, 'clf__min_samples_split': 5, 'clf__n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2025/11/02 18:09:22 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\Anuar\\AppData\\Local\\Temp\\tmpjpbvtjm1\\model\\model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.5.2', 'cloudpickle==2.2.1']. Set logging level to DEBUG to see the full traceback. \n",
      "2025/11/02 18:09:23 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:150: UserWarning: Failed to determine whether UCVolumeDatasetSource can resolve source information for '../data/interim/student_interim_clean_for_model_2.csv'. Exception: \n",
      "  return _dataset_source_registry.resolve(\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:150: UserWarning: The specified dataset source can be interpreted in multiple ways: LocalArtifactDatasetSource, LocalArtifactDatasetSource. MLflow will assume that this is a LocalArtifactDatasetSource source.\n",
      "  return _dataset_source_registry.resolve(\n",
      "2025/11/02 18:09:43 INFO mlflow.tracking._tracking_service.client: 游끢 View run run_3_RF_GridSearch at: http://127.0.0.1:5001/#/experiments/993790272377427900/runs/c9abceea195a44e19eb2a69fb5726af9.\n",
      "2025/11/02 18:09:43 INFO mlflow.tracking._tracking_service.client: 游빍 View experiment at: http://127.0.0.1:5001/#/experiments/993790272377427900.\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registrando corrida 4 con par치metros: {'clf__max_depth': 5, 'clf__min_samples_split': 10, 'clf__n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/02 18:11:43 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\Anuar\\AppData\\Local\\Temp\\tmpflblmrmi\\model\\model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.5.2', 'cloudpickle==2.2.1']. Set logging level to DEBUG to see the full traceback. \n",
      "2025/11/02 18:11:43 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:150: UserWarning: Failed to determine whether UCVolumeDatasetSource can resolve source information for '../data/interim/student_interim_clean_for_model_2.csv'. Exception: \n",
      "  return _dataset_source_registry.resolve(\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:150: UserWarning: The specified dataset source can be interpreted in multiple ways: LocalArtifactDatasetSource, LocalArtifactDatasetSource. MLflow will assume that this is a LocalArtifactDatasetSource source.\n",
      "  return _dataset_source_registry.resolve(\n",
      "2025/11/02 18:12:05 INFO mlflow.tracking._tracking_service.client: 游끢 View run run_4_RF_GridSearch at: http://127.0.0.1:5001/#/experiments/993790272377427900/runs/bb41b4a40aa74e69b80a3db3c19f3397.\n",
      "2025/11/02 18:12:05 INFO mlflow.tracking._tracking_service.client: 游빍 View experiment at: http://127.0.0.1:5001/#/experiments/993790272377427900.\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registrando corrida 5 con par치metros: {'clf__max_depth': 5, 'clf__min_samples_split': 10, 'clf__n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2025/11/02 18:14:05 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\Anuar\\AppData\\Local\\Temp\\tmpotai9yur\\model\\model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.5.2', 'cloudpickle==2.2.1']. Set logging level to DEBUG to see the full traceback. \n",
      "2025/11/02 18:14:05 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:150: UserWarning: Failed to determine whether UCVolumeDatasetSource can resolve source information for '../data/interim/student_interim_clean_for_model_2.csv'. Exception: \n",
      "  return _dataset_source_registry.resolve(\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:150: UserWarning: The specified dataset source can be interpreted in multiple ways: LocalArtifactDatasetSource, LocalArtifactDatasetSource. MLflow will assume that this is a LocalArtifactDatasetSource source.\n",
      "  return _dataset_source_registry.resolve(\n",
      "2025/11/02 18:14:25 INFO mlflow.tracking._tracking_service.client: 游끢 View run run_5_RF_GridSearch at: http://127.0.0.1:5001/#/experiments/993790272377427900/runs/b5cbef462d68479c90686439bff274d1.\n",
      "2025/11/02 18:14:25 INFO mlflow.tracking._tracking_service.client: 游빍 View experiment at: http://127.0.0.1:5001/#/experiments/993790272377427900.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registrando corrida 6 con par치metros: {'clf__max_depth': 5, 'clf__min_samples_split': 10, 'clf__n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2025/11/02 18:16:26 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\Anuar\\AppData\\Local\\Temp\\tmp63jdl9cz\\model\\model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.5.2', 'cloudpickle==2.2.1']. Set logging level to DEBUG to see the full traceback. \n",
      "2025/11/02 18:16:26 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:150: UserWarning: Failed to determine whether UCVolumeDatasetSource can resolve source information for '../data/interim/student_interim_clean_for_model_2.csv'. Exception: \n",
      "  return _dataset_source_registry.resolve(\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:150: UserWarning: The specified dataset source can be interpreted in multiple ways: LocalArtifactDatasetSource, LocalArtifactDatasetSource. MLflow will assume that this is a LocalArtifactDatasetSource source.\n",
      "  return _dataset_source_registry.resolve(\n",
      "2025/11/02 18:16:47 INFO mlflow.tracking._tracking_service.client: 游끢 View run run_6_RF_GridSearch at: http://127.0.0.1:5001/#/experiments/993790272377427900/runs/e22ed7e21c744e1e8215ebb433d16cf7.\n",
      "2025/11/02 18:16:47 INFO mlflow.tracking._tracking_service.client: 游빍 View experiment at: http://127.0.0.1:5001/#/experiments/993790272377427900.\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registrando corrida 7 con par치metros: {'clf__max_depth': 10, 'clf__min_samples_split': 5, 'clf__n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/02 18:18:47 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\Anuar\\AppData\\Local\\Temp\\tmp3p27z2i2\\model\\model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.5.2', 'cloudpickle==2.2.1']. Set logging level to DEBUG to see the full traceback. \n",
      "2025/11/02 18:18:47 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:150: UserWarning: Failed to determine whether UCVolumeDatasetSource can resolve source information for '../data/interim/student_interim_clean_for_model_2.csv'. Exception: \n",
      "  return _dataset_source_registry.resolve(\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:150: UserWarning: The specified dataset source can be interpreted in multiple ways: LocalArtifactDatasetSource, LocalArtifactDatasetSource. MLflow will assume that this is a LocalArtifactDatasetSource source.\n",
      "  return _dataset_source_registry.resolve(\n",
      "2025/11/02 18:19:06 INFO mlflow.tracking._tracking_service.client: 游끢 View run run_7_RF_GridSearch at: http://127.0.0.1:5001/#/experiments/993790272377427900/runs/c0a74d01aa8a4b9694aae7f31a7d0b6d.\n",
      "2025/11/02 18:19:06 INFO mlflow.tracking._tracking_service.client: 游빍 View experiment at: http://127.0.0.1:5001/#/experiments/993790272377427900.\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registrando corrida 8 con par치metros: {'clf__max_depth': 10, 'clf__min_samples_split': 5, 'clf__n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2025/11/02 18:21:06 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\Anuar\\AppData\\Local\\Temp\\tmp8mwokwex\\model\\model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.5.2', 'cloudpickle==2.2.1']. Set logging level to DEBUG to see the full traceback. \n",
      "2025/11/02 18:21:06 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:150: UserWarning: Failed to determine whether UCVolumeDatasetSource can resolve source information for '../data/interim/student_interim_clean_for_model_2.csv'. Exception: \n",
      "  return _dataset_source_registry.resolve(\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:150: UserWarning: The specified dataset source can be interpreted in multiple ways: LocalArtifactDatasetSource, LocalArtifactDatasetSource. MLflow will assume that this is a LocalArtifactDatasetSource source.\n",
      "  return _dataset_source_registry.resolve(\n",
      "2025/11/02 18:21:30 INFO mlflow.tracking._tracking_service.client: 游끢 View run run_8_RF_GridSearch at: http://127.0.0.1:5001/#/experiments/993790272377427900/runs/0aa81e8127014608a97ac6af755c94e7.\n",
      "2025/11/02 18:21:30 INFO mlflow.tracking._tracking_service.client: 游빍 View experiment at: http://127.0.0.1:5001/#/experiments/993790272377427900.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registrando corrida 9 con par치metros: {'clf__max_depth': 10, 'clf__min_samples_split': 5, 'clf__n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2025/11/02 18:23:31 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\Anuar\\AppData\\Local\\Temp\\tmpnw0wv92l\\model\\model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.5.2', 'cloudpickle==2.2.1']. Set logging level to DEBUG to see the full traceback. \n",
      "2025/11/02 18:23:31 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:150: UserWarning: Failed to determine whether UCVolumeDatasetSource can resolve source information for '../data/interim/student_interim_clean_for_model_2.csv'. Exception: \n",
      "  return _dataset_source_registry.resolve(\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:150: UserWarning: The specified dataset source can be interpreted in multiple ways: LocalArtifactDatasetSource, LocalArtifactDatasetSource. MLflow will assume that this is a LocalArtifactDatasetSource source.\n",
      "  return _dataset_source_registry.resolve(\n",
      "2025/11/02 18:23:52 INFO mlflow.tracking._tracking_service.client: 游끢 View run run_9_RF_GridSearch at: http://127.0.0.1:5001/#/experiments/993790272377427900/runs/8dd5bc56da7747cbbec4c648f1438984.\n",
      "2025/11/02 18:23:52 INFO mlflow.tracking._tracking_service.client: 游빍 View experiment at: http://127.0.0.1:5001/#/experiments/993790272377427900.\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registrando corrida 10 con par치metros: {'clf__max_depth': 10, 'clf__min_samples_split': 10, 'clf__n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/02 18:25:52 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\Anuar\\AppData\\Local\\Temp\\tmpu8_qrykd\\model\\model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.5.2', 'cloudpickle==2.2.1']. Set logging level to DEBUG to see the full traceback. \n",
      "2025/11/02 18:25:53 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:150: UserWarning: Failed to determine whether UCVolumeDatasetSource can resolve source information for '../data/interim/student_interim_clean_for_model_2.csv'. Exception: \n",
      "  return _dataset_source_registry.resolve(\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:150: UserWarning: The specified dataset source can be interpreted in multiple ways: LocalArtifactDatasetSource, LocalArtifactDatasetSource. MLflow will assume that this is a LocalArtifactDatasetSource source.\n",
      "  return _dataset_source_registry.resolve(\n",
      "2025/11/02 18:26:29 INFO mlflow.tracking._tracking_service.client: 游끢 View run run_10_RF_GridSearch at: http://127.0.0.1:5001/#/experiments/993790272377427900/runs/4f2f958a4ffd4c20b91cace437871db0.\n",
      "2025/11/02 18:26:29 INFO mlflow.tracking._tracking_service.client: 游빍 View experiment at: http://127.0.0.1:5001/#/experiments/993790272377427900.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!! Este es el mejor modelo (F1-Weighted CV: 0.5031) !!!\n",
      "Registrando corrida 11 con par치metros: {'clf__max_depth': 10, 'clf__min_samples_split': 10, 'clf__n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to interrupt the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel '.venv (Python 3.12.3)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#FUNCIONANDO\n",
    "import mlflow\n",
    "import mlflow.data\n",
    "import mlflow.sklearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# --- IMPORTACIONES DE M칄TRICAS ---\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score\n",
    ")\n",
    "\n",
    "# --- CONFIGURACI칍N DE RUTAS ---\n",
    "DATASET_PATH = '../data/interim/student_interim_clean_for_model_2.csv' \n",
    "DATASET_NAME = 'student_entry_clean'\n",
    "\n",
    "# --- 1. CARGA DE DATOS ---\n",
    "try:\n",
    "    df = pd.read_csv(DATASET_PATH)\n",
    "    print(f\"Dataset cargado desde: {DATASET_PATH}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: Archivo no encontrado en {DATASET_PATH}. Revisa la ruta.\")\n",
    "    exit()\n",
    "\n",
    "# --- 2. L칍GICA DVC: OBTENER EL HASH (DIGEST) ---\n",
    "dvc_digest = None\n",
    "dvc_file_path = DATASET_PATH + \".dvc\"\n",
    "if os.path.exists(dvc_file_path):\n",
    "    try:\n",
    "        with open(dvc_file_path, 'r') as f:\n",
    "            dvc_data = yaml.safe_load(f)\n",
    "        if 'outs' in dvc_data and dvc_data['outs']:\n",
    "            dvc_digest = dvc_data['outs'][0].get('md5') \n",
    "            if not dvc_digest:\n",
    "                dvc_digest = dvc_data['outs'][0].get('checksum') \n",
    "        print(f\"DVC Digest encontrado: {dvc_digest}\")\n",
    "    except Exception as e:\n",
    "        print(f\"ADVERTENCIA: No se pudo leer el archivo DVC. Error: {e}\")\n",
    "\n",
    "# --- 3. PREPARACI칍N DE DATOS Y SPLIT ---\n",
    "X = df.drop(columns=['Performance']) \n",
    "y = df['Performance']\n",
    "cat_cols = ['Gender','Caste','coaching','time','Class_ten_education','twelve_education','medium','Class_ X_Percentage','Class_XII_Percentage','Father_occupation','Mother_occupation']\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_enc = le.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_enc, test_size=0.2, stratify=y_enc, random_state=42)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# --- 4. CONFIGURACI칍N DEL PIPELINE BASE Y LA GRILLA DE B칔SQUEDA ---\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# Pipeline base (solo preprocesamiento y clasificador, sin par치metros a칰n)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('ohe', OneHotEncoder(handle_unknown='ignore'), cat_cols)],\n",
    "    remainder='drop'\n",
    ")\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor), \n",
    "    ('clf', RandomForestClassifier(random_state=888))\n",
    "])\n",
    "\n",
    "# Grilla de Par치metros para GridSearchCV\n",
    "param_grid = {\n",
    "    'clf__n_estimators': [50, 100, 200],  # Cantidad de 치rboles\n",
    "    'clf__max_depth': [5, 10, None],      # Profundidad m치xima\n",
    "    'clf__min_samples_split': [5, 10]     # Muestras m칤nimas para dividir\n",
    "}\n",
    "\n",
    "# Configuraci칩n del Grid Search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1_weighted',\n",
    "    cv=5,                   \n",
    "    verbose=2,\n",
    "    n_jobs=1  # Corregido a 1 para evitar errores de paralelizaci칩n/pickling\n",
    ")\n",
    "\n",
    "# --- 5. ENTRENAMIENTO Y PREDICCIONES (Ejecuci칩n del Grid Search) ---\n",
    "print(\"\\nIniciando Grid Search...\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Grid Search finalizado.\")\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# --- 6. REGISTRO DE TODAS LAS CORRIDAS EN MLFLOW ---\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "MLFLOW_MODEL_NAME = \"Student_Performance_RF_Model\" # Nombre para el Model Registry\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5001\")\n",
    "EXPERIMENT_NAME = \"randomforest_GridSearch\"\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "best_run_id = None\n",
    "best_model_uri = None\n",
    "\n",
    "# Iterar sobre CADA resultado de CV (Cross-Validation)\n",
    "for i, (mean_score, std_score, params) in enumerate(zip(\n",
    "    grid_search.cv_results_['mean_test_score'],\n",
    "    grid_search.cv_results_['std_test_score'],\n",
    "    grid_search.cv_results_['params']\n",
    ")):\n",
    "    \n",
    "    with mlflow.start_run(run_name=f\"run_{i+1}_RF_GridSearch\", nested=True) as run:\n",
    "        print(f\"Registrando corrida {i+1} con par치metros: {params}\")\n",
    "\n",
    "        # --- CORRECCI칍N: LIMPIEZA DE PAR츼METROS ---\n",
    "        # Remueve el prefijo 'clf__' para que RandomForestClassifier lo acepte\n",
    "        clf_params = {k.replace('clf__', ''): v for k, v in params.items()}\n",
    "        # ------------------------------------------\n",
    "        \n",
    "        # Reconstruir el pipeline con los par치metros actuales\n",
    "        current_pipeline = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor), \n",
    "            ('clf', RandomForestClassifier(random_state=888, **clf_params)) \n",
    "        ])\n",
    "        \n",
    "        # Reentrenar el modelo con el conjunto de entrenamiento COMPLETO para este registro\n",
    "        current_pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        # --- C치lculo de M칠tricas ---\n",
    "        y_pred_test = current_pipeline.predict(X_test)\n",
    "        \n",
    "        acc_test = accuracy_score(y_test, y_pred_test)\n",
    "        f1_micro = f1_score(y_test, y_pred_test, average='micro')\n",
    "        f1_macro = f1_score(y_test, y_pred_test, average='macro')\n",
    "        f1_weighted = f1_score(y_test, y_pred_test, average='weighted')\n",
    "        report_text = classification_report(y_test, y_pred_test, target_names=le.classes_)\n",
    "        \n",
    "        metrics = {\n",
    "            \"cv_f1_weighted_mean\": mean_score, \n",
    "            \"cv_f1_weighted_std\": std_score,\n",
    "            \"test_acc\": acc_test,\n",
    "            \"test_f1_weighted\": f1_weighted,\n",
    "            \"test_f1_macro\": f1_macro,\n",
    "        }\n",
    "        \n",
    "        # --- Registro en MLflow ---\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metrics(metrics)\n",
    "        \n",
    "        # 3. Guardar modelo (artefacto)\n",
    "        model_info = mlflow.sklearn.log_model(current_pipeline, \"random_forest_pipeline\")\n",
    "        \n",
    "        # 4. Registrar Dataset y Reporte (artefactos)\n",
    "        mlflow_dataset = mlflow.data.from_pandas(\n",
    "            df=df, source=DATASET_PATH, targets=y.name, name=DATASET_NAME, digest=dvc_digest)\n",
    "        mlflow.log_input(mlflow_dataset, context=\"training\") \n",
    "\n",
    "        temp_report_path = f\"classification_report_run_{i+1}.txt\"\n",
    "        with open(temp_report_path, \"w\") as f:\n",
    "            f.write(report_text)\n",
    "        mlflow.log_artifact(temp_report_path, artifact_path=\"report\")\n",
    "        os.remove(temp_report_path)\n",
    "\n",
    "        # --- Identificaci칩n del Mejor Modelo ---\n",
    "        if mean_score == grid_search.best_score_:\n",
    "             print(f\"!!! Este es el mejor modelo (F1-Weighted CV: {mean_score:.4f}) !!!\")\n",
    "             mlflow.set_tag(\"best_run\", \"True\")\n",
    "             best_run_id = run.info.run_id\n",
    "             best_model_uri = model_info.model_uri # URI para el Model Registry\n",
    "\n",
    "print(\"\\n--- RESUMEN FINAL DE GRID SEARCH ---\")\n",
    "print(f\"El mejor F1-Weighted (CV) es: {grid_search.best_score_:.4f}\")\n",
    "print(f\"Los mejores par치metros son: {grid_search.best_params_}\")\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# --- 7. REGISTRO FINAL DEL MEJOR MODELO EN MODEL REGISTRY ---\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "if best_model_uri:\n",
    "    print(f\"\\n--- REGISTRANDO EL MEJOR MODELO EN REGISTRY ---\")\n",
    "    try:\n",
    "        # Registra el modelo como versi칩n 'initial' en el Registry\n",
    "        model_version = mlflow.register_model(\n",
    "            model_uri=best_model_uri,\n",
    "            name=MLFLOW_MODEL_NAME\n",
    "        )\n",
    "        print(f\"[OK] Modelo '{MLFLOW_MODEL_NAME}' registrado como versi칩n: {model_version.version}\")\n",
    "        print(f\"URI del Modelo: {best_model_uri}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] No se pudo registrar el modelo en el Registry: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
