{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fd86102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cargado desde: ../data/interim/student_interim_clean_for_model_2.csv\n",
      "DVC Digest encontrado: 76db7197326a5942db9c5b100349f69b\n",
      "\n",
      "Iniciando Grid Search...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] END clf__learning_rate=0.05, clf__max_depth=3, clf__n_estimators=50; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.05, clf__max_depth=3, clf__n_estimators=50; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.05, clf__max_depth=3, clf__n_estimators=50; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.05, clf__max_depth=3, clf__n_estimators=50; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.05, clf__max_depth=3, clf__n_estimators=50; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.05, clf__max_depth=3, clf__n_estimators=100; total time=   0.2s\n",
      "[CV] END clf__learning_rate=0.05, clf__max_depth=3, clf__n_estimators=100; total time=   0.2s\n",
      "[CV] END clf__learning_rate=0.05, clf__max_depth=3, clf__n_estimators=100; total time=   0.2s\n",
      "[CV] END clf__learning_rate=0.05, clf__max_depth=3, clf__n_estimators=100; total time=   0.2s\n",
      "[CV] END clf__learning_rate=0.05, clf__max_depth=3, clf__n_estimators=100; total time=   0.2s\n",
      "[CV] END clf__learning_rate=0.05, clf__max_depth=5, clf__n_estimators=50; total time=   0.2s\n",
      "[CV] END clf__learning_rate=0.05, clf__max_depth=5, clf__n_estimators=50; total time=   0.2s\n",
      "[CV] END clf__learning_rate=0.05, clf__max_depth=5, clf__n_estimators=50; total time=   0.2s\n",
      "[CV] END clf__learning_rate=0.05, clf__max_depth=5, clf__n_estimators=50; total time=   0.2s\n",
      "[CV] END clf__learning_rate=0.05, clf__max_depth=5, clf__n_estimators=50; total time=   0.2s\n",
      "[CV] END clf__learning_rate=0.05, clf__max_depth=5, clf__n_estimators=100; total time=   0.6s\n",
      "[CV] END clf__learning_rate=0.05, clf__max_depth=5, clf__n_estimators=100; total time=   0.5s\n",
      "[CV] END clf__learning_rate=0.05, clf__max_depth=5, clf__n_estimators=100; total time=   0.6s\n",
      "[CV] END clf__learning_rate=0.05, clf__max_depth=5, clf__n_estimators=100; total time=   0.5s\n",
      "[CV] END clf__learning_rate=0.05, clf__max_depth=5, clf__n_estimators=100; total time=   0.5s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=3, clf__n_estimators=50; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=3, clf__n_estimators=50; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=3, clf__n_estimators=50; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=3, clf__n_estimators=50; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=3, clf__n_estimators=50; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=3, clf__n_estimators=100; total time=   0.2s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=3, clf__n_estimators=100; total time=   0.3s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=3, clf__n_estimators=100; total time=   0.3s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=3, clf__n_estimators=100; total time=   0.3s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=3, clf__n_estimators=100; total time=   0.3s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=5, clf__n_estimators=50; total time=   0.3s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=5, clf__n_estimators=50; total time=   0.4s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=5, clf__n_estimators=50; total time=   0.3s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=5, clf__n_estimators=50; total time=   0.3s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=5, clf__n_estimators=50; total time=   0.3s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=5, clf__n_estimators=100; total time=   0.7s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=5, clf__n_estimators=100; total time=   0.7s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=5, clf__n_estimators=100; total time=   0.8s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=5, clf__n_estimators=100; total time=   0.8s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=5, clf__n_estimators=100; total time=   0.8s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=3, clf__n_estimators=50; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=3, clf__n_estimators=50; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=3, clf__n_estimators=50; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=3, clf__n_estimators=50; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=3, clf__n_estimators=50; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=3, clf__n_estimators=100; total time=   0.3s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=3, clf__n_estimators=100; total time=   0.3s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=3, clf__n_estimators=100; total time=   0.3s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=3, clf__n_estimators=100; total time=   0.3s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=3, clf__n_estimators=100; total time=   0.3s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=5, clf__n_estimators=50; total time=   0.3s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=5, clf__n_estimators=50; total time=   0.2s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=5, clf__n_estimators=50; total time=   0.3s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=5, clf__n_estimators=50; total time=   0.3s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=5, clf__n_estimators=50; total time=   0.3s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=5, clf__n_estimators=100; total time=   0.7s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=5, clf__n_estimators=100; total time=   0.7s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=5, clf__n_estimators=100; total time=   0.6s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=5, clf__n_estimators=100; total time=   0.6s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=5, clf__n_estimators=100; total time=   0.7s\n",
      "Grid Search finalizado.\n",
      "Registrando corrida 1 con par치metros: {'clf__learning_rate': 0.05, 'clf__max_depth': 3, 'clf__n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2025/11/02 20:01:04 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:150: UserWarning: Failed to determine whether UCVolumeDatasetSource can resolve source information for '../data/interim/student_interim_clean_for_model_2.csv'. Exception: \n",
      "  return _dataset_source_registry.resolve(\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:150: UserWarning: The specified dataset source can be interpreted in multiple ways: LocalArtifactDatasetSource, LocalArtifactDatasetSource. MLflow will assume that this is a LocalArtifactDatasetSource source.\n",
      "  return _dataset_source_registry.resolve(\n",
      "2025/11/02 20:01:21 INFO mlflow.tracking._tracking_service.client: 游끢 View run run_1_GBC_GridSearch at: http://127.0.0.1:5001/#/experiments/972473276069550808/runs/2fae6eb3d9ff40e9b5b1b47799a5c7d6.\n",
      "2025/11/02 20:01:21 INFO mlflow.tracking._tracking_service.client: 游빍 View experiment at: http://127.0.0.1:5001/#/experiments/972473276069550808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registrando corrida 2 con par치metros: {'clf__learning_rate': 0.05, 'clf__max_depth': 3, 'clf__n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/02 20:01:25 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:150: UserWarning: Failed to determine whether UCVolumeDatasetSource can resolve source information for '../data/interim/student_interim_clean_for_model_2.csv'. Exception: \n",
      "  return _dataset_source_registry.resolve(\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:150: UserWarning: The specified dataset source can be interpreted in multiple ways: LocalArtifactDatasetSource, LocalArtifactDatasetSource. MLflow will assume that this is a LocalArtifactDatasetSource source.\n",
      "  return _dataset_source_registry.resolve(\n",
      "2025/11/02 20:01:41 INFO mlflow.tracking._tracking_service.client: 游끢 View run run_2_GBC_GridSearch at: http://127.0.0.1:5001/#/experiments/972473276069550808/runs/89b104be9b6441ed8d912a55460c4b0e.\n",
      "2025/11/02 20:01:41 INFO mlflow.tracking._tracking_service.client: 游빍 View experiment at: http://127.0.0.1:5001/#/experiments/972473276069550808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registrando corrida 3 con par치metros: {'clf__learning_rate': 0.05, 'clf__max_depth': 5, 'clf__n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/02 20:01:43 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:150: UserWarning: Failed to determine whether UCVolumeDatasetSource can resolve source information for '../data/interim/student_interim_clean_for_model_2.csv'. Exception: \n",
      "  return _dataset_source_registry.resolve(\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:150: UserWarning: The specified dataset source can be interpreted in multiple ways: LocalArtifactDatasetSource, LocalArtifactDatasetSource. MLflow will assume that this is a LocalArtifactDatasetSource source.\n",
      "  return _dataset_source_registry.resolve(\n",
      "2025/11/02 20:02:00 INFO mlflow.tracking._tracking_service.client: 游끢 View run run_3_GBC_GridSearch at: http://127.0.0.1:5001/#/experiments/972473276069550808/runs/456a242e9a854eff892dac411bf3db19.\n",
      "2025/11/02 20:02:00 INFO mlflow.tracking._tracking_service.client: 游빍 View experiment at: http://127.0.0.1:5001/#/experiments/972473276069550808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!! Este es el mejor modelo (F1-Weighted CV: 0.5051) !!!\n",
      "Registrando corrida 4 con par치metros: {'clf__learning_rate': 0.05, 'clf__max_depth': 5, 'clf__n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/02 20:02:03 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:150: UserWarning: Failed to determine whether UCVolumeDatasetSource can resolve source information for '../data/interim/student_interim_clean_for_model_2.csv'. Exception: \n",
      "  return _dataset_source_registry.resolve(\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:150: UserWarning: The specified dataset source can be interpreted in multiple ways: LocalArtifactDatasetSource, LocalArtifactDatasetSource. MLflow will assume that this is a LocalArtifactDatasetSource source.\n",
      "  return _dataset_source_registry.resolve(\n",
      "2025/11/02 20:02:18 INFO mlflow.tracking._tracking_service.client: 游끢 View run run_4_GBC_GridSearch at: http://127.0.0.1:5001/#/experiments/972473276069550808/runs/5a232e143c744da1b797d5236bea755c.\n",
      "2025/11/02 20:02:18 INFO mlflow.tracking._tracking_service.client: 游빍 View experiment at: http://127.0.0.1:5001/#/experiments/972473276069550808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registrando corrida 5 con par치metros: {'clf__learning_rate': 0.1, 'clf__max_depth': 3, 'clf__n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/02 20:02:21 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:150: UserWarning: Failed to determine whether UCVolumeDatasetSource can resolve source information for '../data/interim/student_interim_clean_for_model_2.csv'. Exception: \n",
      "  return _dataset_source_registry.resolve(\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:150: UserWarning: The specified dataset source can be interpreted in multiple ways: LocalArtifactDatasetSource, LocalArtifactDatasetSource. MLflow will assume that this is a LocalArtifactDatasetSource source.\n",
      "  return _dataset_source_registry.resolve(\n",
      "2025/11/02 20:02:36 INFO mlflow.tracking._tracking_service.client: 游끢 View run run_5_GBC_GridSearch at: http://127.0.0.1:5001/#/experiments/972473276069550808/runs/bc456972dd494500b4cfbd538c75a9ee.\n",
      "2025/11/02 20:02:36 INFO mlflow.tracking._tracking_service.client: 游빍 View experiment at: http://127.0.0.1:5001/#/experiments/972473276069550808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registrando corrida 6 con par치metros: {'clf__learning_rate': 0.1, 'clf__max_depth': 3, 'clf__n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/02 20:02:39 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:150: UserWarning: Failed to determine whether UCVolumeDatasetSource can resolve source information for '../data/interim/student_interim_clean_for_model_2.csv'. Exception: \n",
      "  return _dataset_source_registry.resolve(\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:150: UserWarning: The specified dataset source can be interpreted in multiple ways: LocalArtifactDatasetSource, LocalArtifactDatasetSource. MLflow will assume that this is a LocalArtifactDatasetSource source.\n",
      "  return _dataset_source_registry.resolve(\n",
      "2025/11/02 20:02:54 INFO mlflow.tracking._tracking_service.client: 游끢 View run run_6_GBC_GridSearch at: http://127.0.0.1:5001/#/experiments/972473276069550808/runs/efcf54062ba54a34955d20dcfc714383.\n",
      "2025/11/02 20:02:54 INFO mlflow.tracking._tracking_service.client: 游빍 View experiment at: http://127.0.0.1:5001/#/experiments/972473276069550808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registrando corrida 7 con par치metros: {'clf__learning_rate': 0.1, 'clf__max_depth': 5, 'clf__n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/02 20:02:57 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:150: UserWarning: Failed to determine whether UCVolumeDatasetSource can resolve source information for '../data/interim/student_interim_clean_for_model_2.csv'. Exception: \n",
      "  return _dataset_source_registry.resolve(\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:150: UserWarning: The specified dataset source can be interpreted in multiple ways: LocalArtifactDatasetSource, LocalArtifactDatasetSource. MLflow will assume that this is a LocalArtifactDatasetSource source.\n",
      "  return _dataset_source_registry.resolve(\n",
      "2025/11/02 20:03:12 INFO mlflow.tracking._tracking_service.client: 游끢 View run run_7_GBC_GridSearch at: http://127.0.0.1:5001/#/experiments/972473276069550808/runs/a4018a330e2b4073b9d97f971ab8c2eb.\n",
      "2025/11/02 20:03:12 INFO mlflow.tracking._tracking_service.client: 游빍 View experiment at: http://127.0.0.1:5001/#/experiments/972473276069550808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registrando corrida 8 con par치metros: {'clf__learning_rate': 0.1, 'clf__max_depth': 5, 'clf__n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/02 20:03:15 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:150: UserWarning: Failed to determine whether UCVolumeDatasetSource can resolve source information for '../data/interim/student_interim_clean_for_model_2.csv'. Exception: \n",
      "  return _dataset_source_registry.resolve(\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:150: UserWarning: The specified dataset source can be interpreted in multiple ways: LocalArtifactDatasetSource, LocalArtifactDatasetSource. MLflow will assume that this is a LocalArtifactDatasetSource source.\n",
      "  return _dataset_source_registry.resolve(\n",
      "2025/11/02 20:03:30 INFO mlflow.tracking._tracking_service.client: 游끢 View run run_8_GBC_GridSearch at: http://127.0.0.1:5001/#/experiments/972473276069550808/runs/70dc92f5586c41e380808c2a37187e76.\n",
      "2025/11/02 20:03:30 INFO mlflow.tracking._tracking_service.client: 游빍 View experiment at: http://127.0.0.1:5001/#/experiments/972473276069550808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registrando corrida 9 con par치metros: {'clf__learning_rate': 0.2, 'clf__max_depth': 3, 'clf__n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/02 20:03:33 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:150: UserWarning: Failed to determine whether UCVolumeDatasetSource can resolve source information for '../data/interim/student_interim_clean_for_model_2.csv'. Exception: \n",
      "  return _dataset_source_registry.resolve(\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:150: UserWarning: The specified dataset source can be interpreted in multiple ways: LocalArtifactDatasetSource, LocalArtifactDatasetSource. MLflow will assume that this is a LocalArtifactDatasetSource source.\n",
      "  return _dataset_source_registry.resolve(\n",
      "2025/11/02 20:03:47 INFO mlflow.tracking._tracking_service.client: 游끢 View run run_9_GBC_GridSearch at: http://127.0.0.1:5001/#/experiments/972473276069550808/runs/4911f377b942465485213757b593134a.\n",
      "2025/11/02 20:03:47 INFO mlflow.tracking._tracking_service.client: 游빍 View experiment at: http://127.0.0.1:5001/#/experiments/972473276069550808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registrando corrida 10 con par치metros: {'clf__learning_rate': 0.2, 'clf__max_depth': 3, 'clf__n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/02 20:03:50 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:150: UserWarning: Failed to determine whether UCVolumeDatasetSource can resolve source information for '../data/interim/student_interim_clean_for_model_2.csv'. Exception: \n",
      "  return _dataset_source_registry.resolve(\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:150: UserWarning: The specified dataset source can be interpreted in multiple ways: LocalArtifactDatasetSource, LocalArtifactDatasetSource. MLflow will assume that this is a LocalArtifactDatasetSource source.\n",
      "  return _dataset_source_registry.resolve(\n",
      "2025/11/02 20:04:06 INFO mlflow.tracking._tracking_service.client: 游끢 View run run_10_GBC_GridSearch at: http://127.0.0.1:5001/#/experiments/972473276069550808/runs/ad0d667e43254d4485518f8feb90f23d.\n",
      "2025/11/02 20:04:06 INFO mlflow.tracking._tracking_service.client: 游빍 View experiment at: http://127.0.0.1:5001/#/experiments/972473276069550808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registrando corrida 11 con par치metros: {'clf__learning_rate': 0.2, 'clf__max_depth': 5, 'clf__n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/02 20:04:08 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:150: UserWarning: Failed to determine whether UCVolumeDatasetSource can resolve source information for '../data/interim/student_interim_clean_for_model_2.csv'. Exception: \n",
      "  return _dataset_source_registry.resolve(\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:150: UserWarning: The specified dataset source can be interpreted in multiple ways: LocalArtifactDatasetSource, LocalArtifactDatasetSource. MLflow will assume that this is a LocalArtifactDatasetSource source.\n",
      "  return _dataset_source_registry.resolve(\n",
      "2025/11/02 20:04:24 INFO mlflow.tracking._tracking_service.client: 游끢 View run run_11_GBC_GridSearch at: http://127.0.0.1:5001/#/experiments/972473276069550808/runs/724056b09fbb4ebba94764e1a77b203a.\n",
      "2025/11/02 20:04:24 INFO mlflow.tracking._tracking_service.client: 游빍 View experiment at: http://127.0.0.1:5001/#/experiments/972473276069550808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registrando corrida 12 con par치metros: {'clf__learning_rate': 0.2, 'clf__max_depth': 5, 'clf__n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/02 20:04:27 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:150: UserWarning: Failed to determine whether UCVolumeDatasetSource can resolve source information for '../data/interim/student_interim_clean_for_model_2.csv'. Exception: \n",
      "  return _dataset_source_registry.resolve(\n",
      "c:\\Users\\Anuar\\Documents\\Maestria Inteligencia artificial\\MLOPs Prueba\\Cookie cutter 2\\proyecto_mlops_equipo_56\\.venv\\Lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:150: UserWarning: The specified dataset source can be interpreted in multiple ways: LocalArtifactDatasetSource, LocalArtifactDatasetSource. MLflow will assume that this is a LocalArtifactDatasetSource source.\n",
      "  return _dataset_source_registry.resolve(\n",
      "2025/11/02 20:04:42 INFO mlflow.tracking._tracking_service.client: 游끢 View run run_12_GBC_GridSearch at: http://127.0.0.1:5001/#/experiments/972473276069550808/runs/69da643cac494681a915779922dd951c.\n",
      "2025/11/02 20:04:42 INFO mlflow.tracking._tracking_service.client: 游빍 View experiment at: http://127.0.0.1:5001/#/experiments/972473276069550808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- RESUMEN FINAL DE GRID SEARCH ---\n",
      "El mejor F1-Weighted (CV) es: 0.5051\n",
      "Los mejores par치metros son: {'clf__learning_rate': 0.05, 'clf__max_depth': 5, 'clf__n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import yaml # Necesario para leer archivos .dvc (YAML)\n",
    "import mlflow\n",
    "import mlflow.data\n",
    "import mlflow.sklearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "# --- CAMBIO CLAVE: Importar GradientBoostingClassifier ---\n",
    "from sklearn.ensemble import GradientBoostingClassifier \n",
    "\n",
    "# --- IMPORTACIONES DE M칄TRICAS ---\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score\n",
    ")\n",
    "\n",
    "# --- CONFIGURACI칍N DE RUTAS ---\n",
    "DATASET_PATH = '../data/interim/student_interim_clean_for_model_2.csv' \n",
    "DATASET_NAME = 'student_entry_clean'\n",
    "\n",
    "# --- 1. CARGA DE DATOS (Mismos pasos) ---\n",
    "try:\n",
    "    df = pd.read_csv(DATASET_PATH)\n",
    "    print(f\"Dataset cargado desde: {DATASET_PATH}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: Archivo no encontrado en {DATASET_PATH}. Revisa la ruta.\")\n",
    "    exit()\n",
    "\n",
    "# --- 2. L칍GICA DVC: OBTENER EL HASH (Mismos pasos) ---\n",
    "dvc_digest = None\n",
    "dvc_file_path = DATASET_PATH + \".dvc\"\n",
    "if os.path.exists(dvc_file_path):\n",
    "    try:\n",
    "        with open(dvc_file_path, 'r') as f:\n",
    "            dvc_data = yaml.safe_load(f)\n",
    "        if 'outs' in dvc_data and dvc_data['outs']:\n",
    "            dvc_digest = dvc_data['outs'][0].get('md5') \n",
    "            if not dvc_digest:\n",
    "                dvc_digest = dvc_data['outs'][0].get('checksum') \n",
    "        print(f\"DVC Digest encontrado: {dvc_digest}\")\n",
    "    except Exception as e:\n",
    "        print(f\"ADVERTENCIA: No se pudo leer el archivo DVC. Error: {e}\")\n",
    "\n",
    "# --- 3. PREPARACI칍N DE DATOS Y SPLIT (Mismos pasos) ---\n",
    "X = df.drop(columns=['Performance']) \n",
    "y = df['Performance']\n",
    "cat_cols = ['Gender','Caste','coaching','time','Class_ten_education','twelve_education','medium','Class_ X_Percentage','Class_XII_Percentage','Father_occupation','Mother_occupation']\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_enc = le.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_enc, test_size=0.2, stratify=y_enc, random_state=42)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# --- 4. CONFIGURACI칍N DEL PIPELINE BASE Y LA GRILLA DE B칔SQUEDA ---\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# Pipeline base (usando GradientBoostingClassifier)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('ohe', OneHotEncoder(handle_unknown='ignore'), cat_cols)],\n",
    "    remainder='drop'\n",
    ")\n",
    "# --- CAMBIO 1: Reemplazamos RandomForestClassifier por GradientBoostingClassifier ---\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor), \n",
    "    ('clf', GradientBoostingClassifier(random_state=888))\n",
    "])\n",
    "\n",
    "# --- CAMBIO 2: Definimos la Grilla de Par치metros para GBC ---\n",
    "param_grid = {\n",
    "    'clf__n_estimators': [50, 100],            # N칰mero de etapas de boosting\n",
    "    'clf__learning_rate': [0.05, 0.1, 0.2],    # Tasa de aprendizaje\n",
    "    'clf__max_depth': [3, 5]                   # Profundidad de cada 치rbol\n",
    "}\n",
    "\n",
    "# Configuraci칩n del Grid Search \n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1_weighted', \n",
    "    cv=5,                   \n",
    "    verbose=2,\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "# --- 5. ENTRENAMIENTO Y PREDICCIONES (Ejecuci칩n del Grid Search) ---\n",
    "print(\"\\nIniciando Grid Search...\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Grid Search finalizado.\")\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# --- 6. REGISTRO DE TODAS LAS CORRIDAS EN MLFLOW (Corregido para GBC) ---\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5001\")\n",
    "# --- CAMBIO 3: Nuevo nombre de experimento para diferenciar el modelo ---\n",
    "EXPERIMENT_NAME = \"gradientboosting_GridSearch\" \n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "\n",
    "# Iterar sobre CADA resultado de CV (Cross-Validation)\n",
    "for i, (mean_score, std_score, params) in enumerate(zip(\n",
    "    grid_search.cv_results_['mean_test_score'],\n",
    "    grid_search.cv_results_['std_test_score'],\n",
    "    grid_search.cv_results_['params']\n",
    ")):\n",
    "    \n",
    "    with mlflow.start_run(run_name=f\"run_{i+1}_GBC_GridSearch\", nested=True) as run:\n",
    "        print(f\"Registrando corrida {i+1} con par치metros: {params}\")\n",
    "\n",
    "        # --- CORRECCI칍N: LIMPIEZA DE PAR츼METROS ---\n",
    "        clf_params = {k.replace('clf__', ''): v for k, v in params.items()}\n",
    "        # ------------------------------------------\n",
    "        \n",
    "        # --- CAMBIO 4: Reconstruir el pipeline con GradientBoostingClassifier ---\n",
    "        current_pipeline = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor), \n",
    "            ('clf', GradientBoostingClassifier(random_state=888, **clf_params)) \n",
    "        ])\n",
    "        \n",
    "        # Entrenar el modelo con el conjunto de entrenamiento COMPLETO\n",
    "        current_pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        # --- Predicciones y C치lculo de M칠tricas (en el conjunto de prueba) ---\n",
    "        y_pred_test = current_pipeline.predict(X_test)\n",
    "        \n",
    "        # Calcular M칠tricas (c칩digo sin cambios)\n",
    "        acc_test = accuracy_score(y_test, y_pred_test)\n",
    "        f1_micro = f1_score(y_test, y_pred_test, average='micro')\n",
    "        f1_macro = f1_score(y_test, y_pred_test, average='macro')\n",
    "        f1_weighted = f1_score(y_test, y_pred_test, average='weighted')\n",
    "        report_text = classification_report(y_test, y_pred_test, target_names=le.classes_)\n",
    "        \n",
    "        metrics = {\n",
    "            \"cv_f1_weighted_mean\": mean_score, \n",
    "            \"cv_f1_weighted_std\": std_score,\n",
    "            \"test_acc\": acc_test,\n",
    "            \"test_f1_weighted\": f1_weighted,\n",
    "            \"test_f1_macro\": f1_macro,\n",
    "        }\n",
    "        \n",
    "        # --- Registro en MLflow (sin cambios, solo se actualizan los datos) ---\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metrics(metrics)\n",
    "        \n",
    "        # Guardar modelo (artefacto)\n",
    "        mlflow.sklearn.log_model(current_pipeline, \"gradient_boosting_pipeline\")\n",
    "        \n",
    "        # Registrar Dataset\n",
    "        mlflow_dataset = mlflow.data.from_pandas(\n",
    "            df=df, source=DATASET_PATH, targets=y.name, name=DATASET_NAME, digest=dvc_digest)\n",
    "        mlflow.log_input(mlflow_dataset, context=\"training\") \n",
    "\n",
    "        # Registrar Classification Report\n",
    "        temp_report_path = f\"classification_report_run_{i+1}.txt\"\n",
    "        with open(temp_report_path, \"w\") as f:\n",
    "            f.write(report_text)\n",
    "        mlflow.log_artifact(temp_report_path, artifact_path=\"report\")\n",
    "        os.remove(temp_report_path)\n",
    "\n",
    "        # Identificaci칩n del Mejor Modelo\n",
    "        if mean_score == grid_search.best_score_:\n",
    "             print(f\"!!! Este es el mejor modelo (F1-Weighted CV: {mean_score:.4f}) !!!\")\n",
    "             mlflow.set_tag(\"best_run\", \"True\")\n",
    "\n",
    "\n",
    "print(\"\\n--- RESUMEN FINAL DE GRID SEARCH ---\")\n",
    "print(f\"El mejor F1-Weighted (CV) es: {grid_search.best_score_:.4f}\")\n",
    "print(f\"Los mejores par치metros son: {grid_search.best_params_}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLOPS Project Environment",
   "language": "python",
   "name": "mlops_env_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
